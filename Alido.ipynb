{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "214a278f",
   "metadata": {},
   "source": [
    "# Supervised Model Cup 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf562b53",
   "metadata": {},
   "source": [
    "Submitted By: Denisse Joyce Alido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885d1395",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6dd69e",
   "metadata": {},
   "source": [
    "APPROACH: Use all models with only their default hyperparameters values (except for those that will produce an error/warning message). Get the model with the highest $F_{1}$ value and tune hyperparameters of said model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65763a8d",
   "metadata": {},
   "source": [
    "Loading Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c4089b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# for splitting of data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to get optimal hyperparameters' values\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7c2466",
   "metadata": {},
   "source": [
    "Creating a dataframe from the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73721154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.197324</td>\n",
       "      <td>0.300926</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.239583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.164345</td>\n",
       "      <td>0.235786</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.165625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.479167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>0.167224</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.091922</td>\n",
       "      <td>0.125418</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.129688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.142061</td>\n",
       "      <td>0.229097</td>\n",
       "      <td>0.337963</td>\n",
       "      <td>0.235938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.060377</td>\n",
       "      <td>0.050696</td>\n",
       "      <td>0.088629</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>0.218750</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.097493</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.103679</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>0.531250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.160535</td>\n",
       "      <td>0.328704</td>\n",
       "      <td>0.170313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>0.781250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.162037</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0   1   2   3   4   5   6   7   8   9   ...  12  13  14  15  \\\n",
       "0     0.750000   1   0   1   1   1   1   1   0   1  ...   1   1   1   1   \n",
       "1     0.239583   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "2     0.479167   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "3     0.656250   0   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "4     0.229167   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "...        ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..   \n",
       "6995  0.875000   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "6996  0.218750   0   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "6997  0.229167   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "6998  0.531250   0   1   1   1   1   1   1   1   1  ...   1   1   1   0   \n",
       "6999  0.781250   1   1   1   1   1   1   1   1   1  ...   1   1   1   1   \n",
       "\n",
       "            16        17        18        19        20  21  \n",
       "0     0.001132  0.080780  0.197324  0.300926  0.225000   1  \n",
       "1     0.000472  0.164345  0.235786  0.537037  0.165625   1  \n",
       "2     0.003585  0.130919  0.167224  0.527778  0.118750   1  \n",
       "3     0.001698  0.091922  0.125418  0.337963  0.129688   1  \n",
       "4     0.000472  0.142061  0.229097  0.337963  0.235938   1  \n",
       "...        ...       ...       ...       ...       ...  ..  \n",
       "6995  0.060377  0.050696  0.088629  0.333333  0.093750  -1  \n",
       "6996  0.004340  0.097493  0.239130  0.347222  0.243750   1  \n",
       "6997  0.005094  0.109192  0.103679  0.291667  0.121875   1  \n",
       "6998  0.002830  0.109192  0.160535  0.328704  0.170313   1  \n",
       "6999  0.001604  0.109192  0.153846  0.162037  0.273438   1  \n",
       "\n",
       "[7000 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"annthyroid-training.csv\", header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914e1f8b",
   "metadata": {},
   "source": [
    "Checking if there are no missing values from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "421c7f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing data\n"
     ]
    }
   ],
   "source": [
    "if df.isnull().sum().sum()==0:\n",
    "    print(\"No missing data\")\n",
    "    \n",
    "else:\n",
    "    print(\"Dataset with missing data\")\n",
    "    print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ce3196",
   "metadata": {},
   "source": [
    "Defining X and y from the dataframe and splitting these data into the training set and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02ff6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df[21]\n",
    "\n",
    "# splitting training and validation data\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X , y, train_size = 0.8, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb47c191",
   "metadata": {},
   "source": [
    "Getting $F_{1}$ value for models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69256f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getF1(tn, fp, fn, tp):\n",
    "    accuracy = (tn+tp)/(tn+fn+fp+tp)\n",
    "    \n",
    "    # sensitivity/recall - ratio between number of true positives and\n",
    "    # the number of all samples whose class is the positive one\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    \n",
    "    # specificity - true negative (correct negative predictions\n",
    "    # to actual negatives) \n",
    "    specificity = tn/(tn+fp)\n",
    "    \n",
    "    # precision - ratio between number of true positives and \n",
    "    # number of all samples classified as positive\n",
    "    precision = tp/(tp+fp)\n",
    "    \n",
    "    f1 = (2*(precision*sensitivity))/(precision+sensitivity)\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f148918",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17500c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 108\n",
      "False Positive: 0\n",
      "False Negative: 4\n",
      "True Positive: 1288\n",
      "0.9984496124031007\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=0) # n_estimators=100 default; no max depth\n",
    "model.fit(train_X, train_y)\n",
    "predictions = model.predict(valid_X)\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(valid_y.values, predictions).ravel()\n",
    "print(\"True Negative: {}\".format(tn))\n",
    "print(\"False Positive: {}\".format(fp))\n",
    "print(\"False Negative: {}\".format(fn))\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "\n",
    "res_RF = getF1(tn, fp, fn, tp)\n",
    "print(res_RF)\n",
    "\n",
    "# creating a dictionary for later use (identifying which model has the best F1 value)\n",
    "dict_results = {'Random Forest Classifier':res_RF}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01a1b76",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "074cd63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 34\n",
      "False Positive: 74\n",
      "False Negative: 6\n",
      "True Positive: 1286\n",
      "0.9698340874811462\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "model.fit(train_X, train_y)\n",
    "predictions = model.predict(valid_X)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(valid_y.values, predictions).ravel()\n",
    "print(\"True Negative: {}\".format(tn))\n",
    "print(\"False Positive: {}\".format(fp))\n",
    "print(\"False Negative: {}\".format(fn))\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "\n",
    "res_KNN = getF1(tn, fp, fn, tp)\n",
    "print(res_KNN)\n",
    "dict_results['K Nearest Neighbors'] = res_KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf7b78a",
   "metadata": {},
   "source": [
    "### Multilayer Perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "368c624c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 102\n",
      "False Positive: 6\n",
      "False Negative: 10\n",
      "True Positive: 1282\n",
      "0.9937984496124032\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(random_state=0, max_iter=10000)\n",
    "# also tried a higher max iter value but f1 value did not increase\n",
    "# max iter fixed warning message\n",
    "\n",
    "model.fit(train_X, train_y)\n",
    "predictions = model.predict(valid_X)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(valid_y.values, predictions).ravel()\n",
    "print(\"True Negative: {}\".format(tn))\n",
    "print(\"False Positive: {}\".format(fp))\n",
    "print(\"False Negative: {}\".format(fn))\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "\n",
    "res_MLP = getF1(tn, fp, fn, tp)\n",
    "print(res_MLP)\n",
    "dict_results['Multilayer Perception'] = res_MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7d8117",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4edd640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 22\n",
      "False Positive: 86\n",
      "False Negative: 0\n",
      "True Positive: 1292\n",
      "0.9677902621722847\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(train_X, train_y)\n",
    "predictions = model.predict(valid_X)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(valid_y.values, predictions).ravel()\n",
    "print(\"True Negative: {}\".format(tn))\n",
    "print(\"False Positive: {}\".format(fp))\n",
    "print(\"False Negative: {}\".format(fn))\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "\n",
    "res_LR = getF1(tn, fp, fn, tp)\n",
    "print(res_LR)\n",
    "dict_results['Logistic Regressor'] = res_LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a68dfe",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5282d3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: 107\n",
      "False Positive: 1\n",
      "False Negative: 1216\n",
      "True Positive: 76\n",
      "0.1110299488677867\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(train_X, train_y)\n",
    "predictions = model.predict(valid_X)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(valid_y.values, predictions).ravel()\n",
    "print(\"True Negative: {}\".format(tn))\n",
    "print(\"False Positive: {}\".format(fp))\n",
    "print(\"False Negative: {}\".format(fn))\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "\n",
    "res_NB = getF1(tn, fp, fn, tp)\n",
    "print(res_NB)\n",
    "dict_results['Naive Bayes'] = res_NB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de090963",
   "metadata": {},
   "source": [
    "Determine which model produced the highest $F_{1}$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97cc654e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model w/ highest F1: Random Forest Classifier\n",
      "F1 Value: 0.9984496124031007\n"
     ]
    }
   ],
   "source": [
    "model_fin = max(dict_results, key=dict_results.get)\n",
    "print(\"Model w/ highest F1: {}\\nF1 Value: {}\".format(model_fin, dict_results[model_fin]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166d51eb",
   "metadata": {},
   "source": [
    "### Tuning of hyperparameters: Apply GridSearchCV to check best hyperparameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beaabba",
   "metadata": {},
   "source": [
    "Applying GridSearchCV to avoid overfitting when getting the best hyperparameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da80f39",
   "metadata": {},
   "source": [
    "Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45140425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2,100]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d35d22",
   "metadata": {},
   "source": [
    "Param grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf9461c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
       " 'max_features': ['auto', 'sqrt', 'log2'],\n",
       " 'max_depth': [2, 100],\n",
       " 'min_samples_split': [2, 5],\n",
       " 'min_samples_leaf': [1, 2],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'bootstrap': bootstrap\n",
    "}\n",
    "\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39979778",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3ea0d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid = GridSearchCV(estimator=model_final, param_grid=param_grid, cv=3, verbose=3, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ceece582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 480 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=0), n_jobs=4,\n",
       "             param_grid={'bootstrap': [True, False], 'max_depth': [2, 100],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [1, 2],\n",
       "                         'min_samples_split': [2, 5],\n",
       "                         'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90,\n",
       "                                          100]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4827aa6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 100,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48864dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier (with hyperparameter tuning):\n",
      "True Negative: 62\n",
      "False Positive: 46\n",
      "False Negative: 3\n",
      "True Positive: 1289\n",
      "Final F1 Value (validation set):  0.9813475447278264\n"
     ]
    }
   ],
   "source": [
    "model_final = RandomForestClassifier(random_state=0, bootstrap=False, max_depth=4, max_features='auto',\n",
    "                                     min_samples_leaf=1, min_samples_split=2, n_estimators=100)\n",
    "model_final.fit(train_X, train_y)\n",
    "predictions = model_final.predict(valid_X)\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(valid_y.values, predictions).ravel()\n",
    "print(\"Random Forest Classifier (with hyperparameter tuning):\")\n",
    "print(\"True Negative: {}\".format(tn))\n",
    "print(\"False Positive: {}\".format(fp))\n",
    "print(\"False Negative: {}\".format(fn))\n",
    "print(\"True Positive: {}\".format(tp))\n",
    "\n",
    "result = getF1(tn, fp, fn, tp)\n",
    "print(\"Final F1 Value (validation set): \",result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f5029e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
